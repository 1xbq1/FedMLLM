## FedMLLM
FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data [arXiv](https://arxiv.org/pdf/2411.14717v2)

| ![Wide Image](https://github.com/1xbq1/FedMLLM/blob/main/assets/Overview.PNG) | ![Narrow Image](https://github.com/1xbq1/FedMLLM/blob/main/assets/Idea.PNG) |
|:-----------------------------:|:--------------------------------:|

## YOCO
You Only Communicate Once: One-shot Federated Learning for Multimodal Large Language Models
> ğŸ† Accepted at **NeurIPS 2025**  

<p align="center">
  <img src="https://github.com/1xbq1/FedMLLM/blob/main/assets/YOCO_idea.PNG" alt="YOCO idea" width="680"/>
</p>
<p align="center">
  <img src="https://github.com/1xbq1/FedMLLM/blob/main/assets/YOCO_overview.PNG" alt="YOCO Overview" width="680"/>
</p>

## TODO
- [x] Release YOCO code: [YOCO Implementation](https://github.com/1xbq1/FedMLLM/tree/yoco/YOCO)

## Directory Structure

<details>
  <summary>Click to expand / collapse</summary>

```base
.
â””â”€â”€ root/
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ hateful_memes/
    â”‚   â”‚   â”œâ”€â”€ minicpmv_data/
    â”‚   â”‚   â”‚   â”œâ”€â”€ modality-missing/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mrate-0.3/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mrate-0.4/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mrate-0.5/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”œâ”€â”€ modality-single/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ image-3/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ image-5/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ image-7/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”œâ”€â”€ modality-mix/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qrate-0.2/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qrate-0.3/
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qrate-0.4/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â”‚   â”œâ”€â”€ partition-alpha5.0-clt10
    â”‚   â”‚   â”‚   â”œâ”€â”€ partition-alpha1.0-clt10
    â”‚   â”‚   â”‚   â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â”‚   â””â”€â”€ raw_data/ # Extracted files of the downloaded dataset
    â”‚   â”‚       â”œâ”€â”€ partition-alpha5.0-clt10
    â”‚   â”‚       â”œâ”€â”€ partition-alpha1.0-clt10
    â”‚   â”‚       â””â”€â”€ partition-alpha0.5-clt10
    â”‚   â””â”€â”€ crisis-mmd # Consistent with the *hateful_memes* folder structure.
    â””â”€â”€ code/
        â”œâ”€â”€ data_gen/
        â”‚   â”œâ”€â”€ data_partition_crisismmd.py
        â”‚   â”œâ”€â”€ data_partition_hateful.py
        â”‚   â”œâ”€â”€ data_process_medalpaca.py
        â”‚   â”œâ”€â”€ data_process_vqarad.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_missing_aug.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_missing.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_mix_aug.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_mix.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_single_aug.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd_single.py
        â”‚   â”œâ”€â”€ gen_data_crisismmd.py
        â”‚   â”œâ”€â”€ gen_data_hateful_missing_aug.py
        â”‚   â”œâ”€â”€ gen_data_hateful_missing.py
        â”‚   â”œâ”€â”€ gen_data_hateful_mix_aug.py
        â”‚   â”œâ”€â”€ gen_data_hateful_mix.py
        â”‚   â”œâ”€â”€ gen_data_hateful_single_aug.py
        â”‚   â”œâ”€â”€ gen_data_hateful_single.py
        â”‚   â”œâ”€â”€ gen_data_hateful.py
        â”‚   â”œâ”€â”€ gen_data_medical_vtqa_single.py
        â”‚   â””â”€â”€ gen_data_medical_vtqa_mix.py
        â”œâ”€â”€ finetune/
        â”‚   â”œâ”€â”€ federated_learning/
        â”‚   â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”‚   â”œâ”€â”€ fed_global.py
        â”‚   â”‚   â””â”€â”€ fed_utils.py
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ dataset.py
        â”‚   â”œâ”€â”€ finetune_lora.sh
        â”‚   â”œâ”€â”€ finetune.py
        â”‚   â””â”€â”€ trainer.py
        â”œâ”€â”€ eval_crisismmd_aug.py
        â”œâ”€â”€ eval_crisismmd.py
        â”œâ”€â”€ eval_hateful_aug.py
        â”œâ”€â”€ eval_hateful.py
        â”œâ”€â”€ eval_medical_gpt_slake.py
        â”œâ”€â”€ eval_medical_gpt.py
        â”œâ”€â”€ eval_medical_slake.py
        â”œâ”€â”€ eval_medical.py
        â”œâ”€â”€ vqa_eval_slake.py
        â”œâ”€â”€ vqa_eval.py
        â”œâ”€â”€ vqa_slake.py
        â”œâ”€â”€ vqa.py
        â””â”€â”€ start.sh
```
</details>

## Install
```Shell
conda create -n FedMLLM python=3.10 -y
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip install -r requirements.txt
```

## Dataset
### Download dataset
1. Hateful-Memes
[download](https://www.kaggle.com/datasets/williamberrios/hateful-memes)
2. CrisisMMD
[download](https://crisisnlp.qcri.org/data/crisismmd/CrisisMMD_v2.0.tar.gz)
3. VQA-RAD
[download](https://www.kaggle.com/datasets/shashankshekhar1205/vqa-rad-visual-question-answering-radiology)
4. MedAlpaca
[download](https://huggingface.co/datasets/medalpaca/medical_meadow_medical_flashcards)
5. SLAKE
[download](https://www.med-vqa.com/slake/)
### Dataset processing
```bash
cd data_gen/

python data_partition_crisismmd.py
python gen_data_crisismmd.py # aligned modal scenario
python gen_data_crisismmd_missing.py # missing modal scenario
python gen_data_crisismmd_missing_aug.py # missing modal scenario with prompt strategy
python gen_data_crisismmd_single.py # cross modal scenario
python gen_data_crisismmd_mix.py # hybrid modal scenario

python data_process_medalpaca.py
python data_process_vqarad.py
python gen_data_medical_vtqa_mix.py
python gen_data_medical_vtqa_single.py
```

## Training and Testing
```
sh start.sh
```

## Citation
```
@article{xu2024fedmllm,
  title={FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data},
  author={Xu, Binqian and Shu, Xiangbo and Mei, Haiyang and Xie, Guosen and Fernando, Basura and Tang, Jinhui},
  journal={arXiv preprint arXiv:2411.14717},
  year={2024}
}

@inproceedings{xu2025you,
  title={You Only Communicate Once: One-shot Federated Low-Rank Adaptation of MLLM},
  author={Binqian Xu, Haiyang Mei, Zechen Bai, Jinjin Gong, Rui Yan, Guo-Sen Xie, Yazhou Yao, Basura Fernando, Xiangbo Shu},
  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems}
}

```

## Acknowledgements
This repo is based on [MiniCPM-V](https://github.com/OpenBMB/MiniCPM-V), [OpenFedLLM](https://github.com/rui-ye/OpenFedLLM), and [PeFoMed](https://github.com/jinlHe/PeFoMed/tree/main) thanks to the original authors for their works!
